{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4e7cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, request, jsonify, render_template\n",
    "# from google.cloud import texttospeech\n",
    "# import os\n",
    "# import uuid\n",
    "# from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "# from ibm_watsonx_ai.client import APIClient\n",
    "\n",
    "# # Initialize Flask app\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# # Load configuration from config.py\n",
    "# app.config.from_object('config')  # Ensure config.py is in the same directory as app.py\n",
    "\n",
    "# # Initialize Google TTS client\n",
    "# tts_client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "# # Initialize IBM Watson Model client with settings from config\n",
    "# credentials = {\n",
    "#     \"apikey\": app.config[\"API_KEY\"],\n",
    "#     \"url\": app.config[\"SERVICE_URL\"]\n",
    "# }\n",
    "# api_client = APIClient(credentials)\n",
    "\n",
    "# # Add project_id or space_id as needed\n",
    "# model = ModelInference(\n",
    "#     api_client=api_client,\n",
    "#     model_id=app.config[\"MODEL_ID\"],\n",
    "#     project_id=app.config.get(\"PROJECT_ID\"),  # Use project_id if available\n",
    "# )\n",
    "\n",
    "# @app.route('/')\n",
    "# def home():\n",
    "#     return render_template('index.html')\n",
    "\n",
    "# @app.route('/process', methods=['POST'])\n",
    "# def process_data():\n",
    "#     data = request.json\n",
    "#     question = data.get(\"question\")\n",
    "#     response_text = generate_response(question)\n",
    "   \n",
    "#     # Generate audio from response using Google TTS\n",
    "#     audio_path = generate_tts(response_text)\n",
    "#     return jsonify(response=response_text, audio=audio_path)\n",
    "\n",
    "# def generate_response(user_input):\n",
    "#     # Construct a prompt to guide model response\n",
    "#     prompt = f\"\"\"\n",
    "    \n",
    "# المهمة الرئيسية:\n",
    "# تعليم اللغة العربية من خلال إجراء حوار مع المستخدم\n",
    "\n",
    "# التعليمات:\n",
    "# اسأل المتسخدم عن اسمه\n",
    "# مثال:\n",
    "# اهلا وسهلا بك اسمي علام أنا هنا لمساعدتك في تعلم اللغة العربية ما اسمك؟\n",
    "\n",
    "# ثم\n",
    "\n",
    "# اعرض على المستخدم مواضيع الحوارات\n",
    "\n",
    "# مثال:\n",
    "#  اهلا يا .......... اختر واحداً من هذه المواضيع لنقوم أنا وأنت بإجراء حوار حول هذا الموضوع \n",
    "# 1. في المطار\n",
    "# 2. في الجامعة\n",
    "# 3. في السوق\n",
    "# 4. في في المنزل \n",
    "# 5. حوار عن الجو..\n",
    "# 6. شراء هاتف جوال \n",
    "  \n",
    "# ثم انشأ حوار مبسط لمستوى مبتدئ مع المستخدم\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  ثم\n",
    "\n",
    "#  اعد الحوار مع المستخدم بحيث تقوم أنت بتأدية أحد الأدوار والمستخدم يقوم بالدور الآخر\n",
    "# مثال:\n",
    "# يؤدي المستخدم دوره :\n",
    "\n",
    "# بعد أن كتب المستخدم دوره  تقوم أنت بدورك :\n",
    "\n",
    "# يؤدي المستخدم دوره :\n",
    "\n",
    "# بعد أن كتب المستخدم دوره  تقوم أنت بدورك:\n",
    "\n",
    "\n",
    "# يؤدي المستخدم دوره :\n",
    "\n",
    "# بعد أن كتب المستخدم دوره  تقوم أنت بدورك:\n",
    "\n",
    "\n",
    "\n",
    "#     <</SYS>>\n",
    "\n",
    "#     User: {user_input}\n",
    "#     Bot:\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Generate response from the model using only the prompt\n",
    "#     response = model.generate_text(prompt=prompt)\n",
    "#     return response.strip()\n",
    "\n",
    "# def generate_tts(text):\n",
    "#     # Configure TTS request for Google Cloud\n",
    "#     synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "#     voice = texttospeech.VoiceSelectionParams(language_code=\"ar-SA\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL)\n",
    "#     audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
    "\n",
    "#     # Perform the text-to-speech request\n",
    "#     response = tts_client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
    "\n",
    "#     # Save audio to a temporary file\n",
    "#     audio_filename = f\"{uuid.uuid4()}.mp3\"\n",
    "#     audio_path = os.path.join(\"static\", audio_filename)\n",
    "#     with open(audio_path, \"wb\") as out:\n",
    "#         out.write(response.audio_content)\n",
    "#         print(f'Audio content written to file \"{audio_path}\"')\n",
    "   \n",
    "#     return audio_path\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "355a2bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, request, jsonify, render_template\n",
    "# from google.cloud import texttospeech\n",
    "# import os\n",
    "# import uuid\n",
    "# from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "# from ibm_watsonx_ai.client import APIClient\n",
    "\n",
    "# # Initialize Flask app\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# # Load configuration from config.py\n",
    "# app.config.from_object('config')\n",
    "\n",
    "# # Initialize Google TTS client\n",
    "# tts_client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "# # Initialize IBM Watson Model client with settings from config\n",
    "# credentials = {\n",
    "#     \"apikey\": app.config[\"API_KEY\"],\n",
    "#     \"url\": app.config[\"SERVICE_URL\"]\n",
    "# }\n",
    "# api_client = APIClient(credentials)\n",
    "\n",
    "# # Add project_id or space_id as needed\n",
    "# model = ModelInference(\n",
    "#     api_client=api_client,\n",
    "#     model_id=app.config[\"MODEL_ID\"],\n",
    "#     project_id=app.config.get(\"PROJECT_ID\")\n",
    "# )\n",
    "\n",
    "# # Memory to store conversation context\n",
    "# conversation_memory = []\n",
    "\n",
    "# @app.route('/')\n",
    "# def home():\n",
    "#     return render_template('index.html')\n",
    "\n",
    "# @app.route('/process', methods=['POST'])\n",
    "# def process_data():\n",
    "#     data = request.json\n",
    "#     question = data.get(\"question\")\n",
    "#     response_text = generate_response(question)\n",
    "   \n",
    "#     # Generate audio from response using Google TTS\n",
    "#     audio_path = generate_tts(response_text)\n",
    "#     return jsonify(response=response_text, audio=audio_path)\n",
    "\n",
    "# def generate_response(user_input):\n",
    "#     # Append user input to conversation memory\n",
    "#     conversation_memory.append(f\"المستخدم: {user_input}\")\n",
    "    \n",
    "#     # Structure prompts in segments to reduce truncation\n",
    "#     segmented_prompts = [\n",
    "#         \"علام: مرحبًا بك في جلسة تعلم اللغة العربية! ما هو اسمك؟\",\n",
    "#         \"علام: من فضلك اختر موضوعًا من القائمة التالية:\",\n",
    "#         \"علام: هل ترغب في دور الزبون أم البائع؟\",\n",
    "#         \"علام: لنبدأ الحوار. كيف يمكنني مساعدتك؟\",\n",
    "#         \"علام: شكرًا لك! هل ترغب في تجربة موضوع آخر؟\"\n",
    "#     ]\n",
    "\n",
    "#     response = \"\"\n",
    "#     for prompt in segmented_prompts:\n",
    "#         # Generate each response segment and store it in conversation memory\n",
    "#         full_prompt = \"\\n\".join(conversation_memory) + \"\\n\" + prompt\n",
    "#         segment_response = model.generate_text(prompt=full_prompt).strip()\n",
    "\n",
    "#         # Continue until a complete response is generated for each segment\n",
    "#         if segment_response.endswith(\"...\") or len(segment_response) < 30:\n",
    "#             segment_response += model.generate_text(prompt=prompt + \" اكمل الجواب:\").strip()\n",
    "        \n",
    "#         # Append each segment response to the conversation memory and main response\n",
    "#         conversation_memory.append(f\"علام: {segment_response}\")\n",
    "#         response += \"\\n\" + segment_response\n",
    "    \n",
    "#     return response\n",
    "\n",
    "# def generate_tts(text):\n",
    "#     synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "#     voice = texttospeech.VoiceSelectionParams(language_code=\"ar-SA\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL)\n",
    "#     audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
    "\n",
    "#     response = tts_client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
    "\n",
    "#     audio_filename = f\"{uuid.uuid4()}.mp3\"\n",
    "#     audio_path = os.path.join(\"static\", audio_filename)\n",
    "#     with open(audio_path, \"wb\") as out:\n",
    "#         out.write(response.audio_content)\n",
    "#         print(f'Audio content written to file \"{audio_path}\"')\n",
    "   \n",
    "#     return audio_path\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34c3d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, request, jsonify, render_template\n",
    "# from google.cloud import texttospeech\n",
    "# import os\n",
    "# import uuid\n",
    "# from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "# from ibm_watsonx_ai.client import APIClient\n",
    "\n",
    "# # Initialize Flask app\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# # Load configuration from config.py\n",
    "# app.config.from_object('config')\n",
    "\n",
    "# # Initialize Google TTS client\n",
    "# tts_client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "# # Initialize IBM Watson Model client with settings from config\n",
    "# credentials = {\n",
    "#     \"apikey\": app.config[\"API_KEY\"],\n",
    "#     \"url\": app.config[\"SERVICE_URL\"]\n",
    "# }\n",
    "# api_client = APIClient(credentials)\n",
    "\n",
    "# # Add project_id or space_id as needed\n",
    "# model = ModelInference(\n",
    "#     api_client=api_client,\n",
    "#     model_id=app.config[\"MODEL_ID\"],\n",
    "#     project_id=app.config.get(\"PROJECT_ID\")\n",
    "# )\n",
    "\n",
    "# @app.route('/')\n",
    "# def home():\n",
    "#     return render_template('index.html')\n",
    "\n",
    "# @app.route('/process', methods=['POST'])\n",
    "# def process_data():\n",
    "#     data = request.json\n",
    "#     question = data.get(\"question\")\n",
    "#     response_text = generate_response(question)\n",
    "   \n",
    "#     # Generate audio from response using Google TTS\n",
    "#     audio_path = generate_tts(response_text)\n",
    "#     return jsonify(response=response_text, audio=audio_path)\n",
    "\n",
    "# def generate_response(user_input):\n",
    "#     # Base system prompt to guide Allam in a structured, beginner-friendly conversation\n",
    "#     system_prompt = \"\"\"\n",
    "#     <<SYS>>\n",
    "#     أنت \"علام\"، مساعد لتعليم اللغة العربية من خلال حوارات بسيطة. الهدف هو الحفاظ على حوار باللغة العربية فقط، باستخدام جمل قصيرة وبسيطة.\n",
    "    \n",
    "#     التعليمات:\n",
    "#     1. قدم نفسك واسأل عن اسم المستخدم.\n",
    "#     2. عند معرفة اسم المستخدم، اعرض عليه المواضيع للاختيار.\n",
    "#     3. بناءً على الموضوع الذي يختاره، اسأله عن الدور الذي يريد تأديته.\n",
    "#     4. في الحوار، تأكد من أن كل سؤال منطقي ومباشر، مع تقديم إجابات قصيرة وسهلة الفهم.\n",
    "#     5. عند انتهاء الحوار، اسأل المستخدم إذا كان يريد تجربة موضوع آخر.\n",
    "\n",
    "#     تذكر، اجعل إجاباتك موجزة وبسيطة، وابقَ ضمن موضوع الحوار دون الخروج عنه.\n",
    "#     <<SYS>>\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Conversation steps to ensure logical responses\n",
    "#     steps = [\n",
    "#         {\"prompt\": \"علام: مرحبًا! أنا علام، مساعدك في تعلم اللغة العربية. ما اسمك؟\", \"expect\": \"الاسم\"},\n",
    "#         {\"prompt\": \"علام: سررت بمعرفتك! اختر موضوعًا لبدء الحوار:\\n1. في السوق\\n2. في المطعم\\n3. في المطار\\n4. في المستشفى\", \"expect\": \"الموضوع\"},\n",
    "#         {\"prompt\": \"علام: رائع! هل ترغب في أن تكون الزبون أم البائع؟\", \"expect\": \"الدور\"},\n",
    "#         {\"prompt\": \"علام: لنبدأ الحوار! كيف يمكنني مساعدتك اليوم؟\", \"expect\": \"الحوار\"},\n",
    "#         {\"prompt\": \"علام: شكرًا لك على هذا الحوار! هل ترغب في تجربة موضوع آخر؟\", \"expect\": \"نهاية\"}\n",
    "#     ]\n",
    "\n",
    "#     # Determine the conversation step based on previous memory or new input\n",
    "#     conversation_memory = []\n",
    "\n",
    "#     for step in steps:\n",
    "#         # Build the prompt with the context from the system and current step\n",
    "#         full_prompt = system_prompt + \"\\n\" + \"\\n\".join(conversation_memory) + \"\\n\" + step[\"prompt\"]\n",
    "\n",
    "#         # Generate response for each step\n",
    "#         response = model.generate_text(prompt=full_prompt).strip()\n",
    "        \n",
    "#         # Ensure response is logical and relevant to the prompt\n",
    "#         if response.endswith(\"...\") or len(response) < 30:\n",
    "#             response += model.generate_text(prompt=step[\"prompt\"] + \" اكمل الجواب:\").strip()\n",
    "        \n",
    "#         # Store response in conversation memory\n",
    "#         conversation_memory.append(f\"علام: {response}\")\n",
    "        \n",
    "#         # If response meets the expectation, continue to the next step\n",
    "#         if step[\"expect\"] in [\"الاسم\", \"الموضوع\", \"الدور\", \"الحوار\", \"نهاية\"]:\n",
    "#             conversation_memory.append(f\"المستخدم: {user_input}\")\n",
    "\n",
    "#     return \"\\n\".join(conversation_memory)\n",
    "\n",
    "# def generate_tts(text):\n",
    "#     # Configure TTS request for Google Cloud\n",
    "#     synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "#     voice = texttospeech.VoiceSelectionParams(language_code=\"ar-SA\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL)\n",
    "#     audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
    "\n",
    "#     # Perform the text-to-speech request\n",
    "#     response = tts_client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
    "\n",
    "#     # Save audio to a temporary file\n",
    "#     audio_filename = f\"{uuid.uuid4()}.mp3\"\n",
    "#     audio_path = os.path.join(\"static\", audio_filename)\n",
    "#     with open(audio_path, \"wb\") as out:\n",
    "#         out.write(response.audio_content)\n",
    "#         print(f'Audio content written to file \"{audio_path}\"')\n",
    "   \n",
    "#     return audio_path\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08a29a1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m app\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mfrom_object(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Ensure config.py is in the same directory as app.py\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Initialize Google TTS client\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m tts_client \u001b[38;5;241m=\u001b[39m texttospeech\u001b[38;5;241m.\u001b[39mTextToSpeechClient()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize IBM Watson Model client with settings from config\u001b[39;00m\n\u001b[0;32m     18\u001b[0m credentials \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapikey\u001b[39m\u001b[38;5;124m\"\u001b[39m: app\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: app\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSERVICE_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     21\u001b[0m }\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\texttospeech_v1\\services\\text_to_speech\\client.py:669\u001b[0m, in \u001b[0;36mTextToSpeechClient.__init__\u001b[1;34m(self, credentials, transport, client_options, client_info)\u001b[0m\n\u001b[0;32m    661\u001b[0m transport_init: Union[\n\u001b[0;32m    662\u001b[0m     Type[TextToSpeechTransport], Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, TextToSpeechTransport]\n\u001b[0;32m    663\u001b[0m ] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, TextToSpeechTransport], transport)\n\u001b[0;32m    667\u001b[0m )\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[1;32m--> 669\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport \u001b[38;5;241m=\u001b[39m transport_init(\n\u001b[0;32m    670\u001b[0m     credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[0;32m    671\u001b[0m     credentials_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_options\u001b[38;5;241m.\u001b[39mcredentials_file,\n\u001b[0;32m    672\u001b[0m     host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_endpoint,\n\u001b[0;32m    673\u001b[0m     scopes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_options\u001b[38;5;241m.\u001b[39mscopes,\n\u001b[0;32m    674\u001b[0m     client_cert_source_for_mtls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_cert_source,\n\u001b[0;32m    675\u001b[0m     quota_project_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_options\u001b[38;5;241m.\u001b[39mquota_project_id,\n\u001b[0;32m    676\u001b[0m     client_info\u001b[38;5;241m=\u001b[39mclient_info,\n\u001b[0;32m    677\u001b[0m     always_use_jwt_access\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    678\u001b[0m     api_audience\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_options\u001b[38;5;241m.\u001b[39mapi_audience,\n\u001b[0;32m    679\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\texttospeech_v1\\services\\text_to_speech\\transports\\grpc.py:153\u001b[0m, in \u001b[0;36mTextToSpeechGrpcTransport.__init__\u001b[1;34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_channel_credentials \u001b[38;5;241m=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mssl_channel_credentials(\n\u001b[0;32m    149\u001b[0m                 certificate_chain\u001b[38;5;241m=\u001b[39mcert, private_key\u001b[38;5;241m=\u001b[39mkey\n\u001b[0;32m    150\u001b[0m             )\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    154\u001b[0m     host\u001b[38;5;241m=\u001b[39mhost,\n\u001b[0;32m    155\u001b[0m     credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[0;32m    156\u001b[0m     credentials_file\u001b[38;5;241m=\u001b[39mcredentials_file,\n\u001b[0;32m    157\u001b[0m     scopes\u001b[38;5;241m=\u001b[39mscopes,\n\u001b[0;32m    158\u001b[0m     quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id,\n\u001b[0;32m    159\u001b[0m     client_info\u001b[38;5;241m=\u001b[39mclient_info,\n\u001b[0;32m    160\u001b[0m     always_use_jwt_access\u001b[38;5;241m=\u001b[39malways_use_jwt_access,\n\u001b[0;32m    161\u001b[0m     api_audience\u001b[38;5;241m=\u001b[39mapi_audience,\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grpc_channel:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     channel_init \u001b[38;5;241m=\u001b[39m channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreate_channel\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\texttospeech_v1\\services\\text_to_speech\\transports\\base.py:100\u001b[0m, in \u001b[0;36mTextToSpeechTransport.__init__\u001b[1;34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mload_credentials_from_file(\n\u001b[0;32m     97\u001b[0m         credentials_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[0;32m     98\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_credentials:\n\u001b[1;32m--> 100\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mdefault(\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_gdch_audience\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\auth\\_default.py:691\u001b[0m, in \u001b[0;36mdefault\u001b[1;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[0;32m    683\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    684\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    685\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    686\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    687\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[0;32m    688\u001b[0m             )\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[1;32m--> 691\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from google.cloud import texttospeech\n",
    "import os\n",
    "import uuid\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.client import APIClient\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load configuration from config.py\n",
    "app.config.from_object('config')  # Ensure config.py is in the same directory as app.py\n",
    "\n",
    "# Initialize Google TTS client\n",
    "tts_client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "# Initialize IBM Watson Model client with settings from config\n",
    "credentials = {\n",
    "    \"apikey\": app.config[\"API_KEY\"],\n",
    "    \"url\": app.config[\"SERVICE_URL\"]\n",
    "}\n",
    "api_client = APIClient(credentials)\n",
    "\n",
    "# Add project_id or space_id as needed\n",
    "model = ModelInference(\n",
    "    api_client=api_client,\n",
    "    model_id=app.config[\"MODEL_ID\"],\n",
    "    project_id=app.config.get(\"PROJECT_ID\"),  # Use project_id if available\n",
    ")\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/process', methods=['POST'])\n",
    "def process_data():\n",
    "    data = request.json\n",
    "    question = data.get(\"question\")\n",
    "    response_text = generate_response(question)\n",
    "   \n",
    "    # Generate audio from response using Google TTS\n",
    "    audio_path = generate_tts(response_text)\n",
    "    return jsonify(response=response_text, audio=audio_path)\n",
    "\n",
    "def generate_response(user_input):\n",
    "    # Construct a prompt to guide model response\n",
    "    prompt = f\"\"\"\n",
    "    \n",
    "المهمة الرئيسية:\n",
    "تعليم اللغة العربية من خلال إجراء حوار مع المستخدم\n",
    "\n",
    "التعليمات:\n",
    "اسأل المتسخدم عن اسمه\n",
    "مثال:\n",
    "اهلا وسهلا بك اسمي علام أنا هنا لمساعدتك في تعلم اللغة العربية ما اسمك؟\n",
    "\n",
    "ثم\n",
    "\n",
    "اعرض على المستخدم مواضيع الحوارات\n",
    "\n",
    "مثال:\n",
    " اهلا يا .......... اختر واحداً من هذه المواضيع لنقوم أنا وأنت بإجراء حوار حول هذا الموضوع \n",
    "1. في المطار\n",
    "2. في الجامعة\n",
    "3. في السوق\n",
    "4. في في المنزل \n",
    "5. حوار عن الجو..\n",
    "6. شراء هاتف جوال \n",
    "  \n",
    "ثم انشأ حوار مبسط لمستوى مبتدئ مع المستخدم\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " ثم\n",
    "\n",
    " اعد الحوار مع المستخدم بحيث تقوم أنت بتأدية أحد الأدوار والمستخدم يقوم بالدور الآخر\n",
    "مثال:\n",
    "يؤدي المستخدم دوره :\n",
    "\n",
    "بعد أن كتب المستخدم دوره  تقوم أنت بدورك :\n",
    "\n",
    "يؤدي المستخدم دوره :\n",
    "\n",
    "بعد أن كتب المستخدم دوره  تقوم أنت بدورك:\n",
    "\n",
    "\n",
    "يؤدي المستخدم دوره :\n",
    "\n",
    "بعد أن كتب المستخدم دوره  تقوم أنت بدورك:\n",
    "\n",
    "\n",
    "\n",
    "    <</SYS>>\n",
    "\n",
    "    User: {user_input}\n",
    "    Bot:\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response from the model using only the prompt\n",
    "    response = model.generate_text(prompt=prompt)\n",
    "    return response.strip()\n",
    "\n",
    "def generate_tts(text):\n",
    "    # Configure TTS request for Google Cloud\n",
    "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "    voice = texttospeech.VoiceSelectionParams(language_code=\"ar-SA\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL)\n",
    "    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
    "\n",
    "    # Perform the text-to-speech request\n",
    "    response = tts_client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
    "\n",
    "    # Save audio to a temporary file\n",
    "    audio_filename = f\"{uuid.uuid4()}.mp3\"\n",
    "    audio_path = os.path.join(\"static\", audio_filename)\n",
    "    with open(audio_path, \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "        print(f'Audio content written to file \"{audio_path}\"')\n",
    "   \n",
    "    return audio_path\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac0c109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
